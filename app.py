import streamlit as st
import os
import json
import pandas as pd
import re
from dotenv import load_dotenv
from openai import OpenAI
from tavily import TavilyClient

# ============================================================================
# 1. åŸºç¡€é…ç½®
# ============================================================================
st.set_page_config(
    page_title="Crypto BD Hunter: Architect Edition",
    page_icon="âš”ï¸",
    layout="wide"
)

# è‡ªå®šä¹‰ CSS ä¼˜åŒ–è¡¨æ ¼æ˜¾ç¤º
st.markdown("""
<style>
    .stDataFrame { border: 1px solid #f0f0f0; border-radius: 5px; }
    div[data-testid="stStatusWidget"] { font-weight: bold; }
</style>
""", unsafe_allow_html=True)

load_dotenv()

with st.sidebar:
    st.header("âš™ï¸ æ ¸å¿ƒå¼•æ“")
    deepseek_key = st.text_input("DeepSeek Key", value=os.getenv("DEEPSEEK_API_KEY", ""), type="password")
    tavily_key = st.text_input("Tavily Key", value=os.getenv("TAVILY_API_KEY", ""), type="password")
    st.info("ğŸ’¡ Tip: å³ä½¿å¡«åäº†æ¨ç‰¹å’Œå®˜ç½‘ï¼Œç³»ç»Ÿç°åœ¨ä¹Ÿèƒ½è‡ªåŠ¨è¯†åˆ«ã€‚")

if not deepseek_key or not tavily_key:
    st.warning("âš ï¸ è¯·å…ˆé…ç½® API Keys")
    st.stop()

# åˆå§‹åŒ–å®¢æˆ·ç«¯
try:
    llm = OpenAI(api_key=deepseek_key, base_url="https://api.deepseek.com")
    tavily = TavilyClient(api_key=tavily_key)
except Exception as e:
    st.error(f"Client Init Error: {e}")
    st.stop()

# ============================================================================
# 2. æ™ºèƒ½è¾“å…¥å¤„ç† (Smart Input Processor)
# ============================================================================

def auto_detect_fingerprints(input_website, input_twitter):
    """
    ä¸ç®¡ç”¨æˆ·å¡«åœ¨å“ªä¸ªæ¡†ï¼Œè‡ªåŠ¨è¯†åˆ«è°æ˜¯å®˜ç½‘ï¼Œè°æ˜¯æ¨ç‰¹ã€‚
    """
    fingerprints = {
        "twitter_handle": None,
        "domain": None
    }
    
    # åˆå¹¶è¾“å…¥è¿›è¡Œåˆ†æ
    inputs = [input_website, input_twitter]
    
    for item in inputs:
        if not item: continue
        item = item.strip().lower()
        
        # è¯†åˆ«æ¨ç‰¹
        if "x.com" in item or "twitter.com" in item:
            # æå– handle: x.com/Weex_Official -> Weex_Official
            try:
                # ç§»é™¤æœ«å°¾æ–œæ å’Œå‚æ•°
                clean_url = item.split("?")[0].rstrip("/")
                handle = clean_url.split("/")[-1]
                if handle:
                    fingerprints["twitter_handle"] = handle
            except:
                pass
        
        # è¯†åˆ«å®˜ç½‘ (æ’é™¤æ¨ç‰¹ã€é¢†è‹±)
        elif "." in item and "linkedin" not in item:
            # æå–åŸŸå: https://www.weex.com/ -> weex.com
            try:
                clean_url = item.replace("https://", "").replace("http://", "").split("/")[0]
                # ç§»é™¤ www.
                if clean_url.startswith("www."):
                    clean_url = clean_url[4:]
                fingerprints["domain"] = clean_url
            except:
                pass
                
    return fingerprints

# ============================================================================
# 3. ç€‘å¸ƒæµæœç´¢ç­–ç•¥ (Waterfall Search Strategy)
# ============================================================================

def generate_waterfall_queries(project_name, category, fps):
    queries = []
    
    # åŸºç¡€è¿‡æ»¤ï¼šå¼ºåˆ¶ Crypto ä¸Šä¸‹æ–‡ + æ’é™¤é¤å…/å®ä½“åº—
    base_context = "crypto OR blockchain OR web3 OR exchange OR token"
    negative_filter = "-restaurant -steakhouse -chef -menu -food -dining -recipe"
    
    # è§’è‰²å…³é”®è¯
    if category == "VC":
        roles = "Partner OR Investor"
    else:
        roles = "Founder OR CEO OR CMO OR \"Head of Listing\" OR \"Head of BD\""

    # --- Level 1: ç²¾å‡†ç‹™å‡» (å¦‚æœæŒ‡çº¹å­˜åœ¨) ---
    # é€»è¾‘ï¼šå¾ˆå¤š Crypto äººçš„é¢†è‹±ç®€ä»‹ä¼šå†™ "Founder @Weex_Official"
    if fps["twitter_handle"]:
        queries.append(f"site:linkedin.com \"@{fps['twitter_handle']}\"")
        queries.append(f"site:linkedin.com \"{fps['twitter_handle']}\"")
    
    if fps["domain"]:
        queries.append(f"site:linkedin.com \"{fps['domain']}\" {roles}")

    # --- Level 2: å¼ºå…³è”æœç´¢ (é¡¹ç›®å + è¡Œä¸šè¯) ---
    # é€»è¾‘ï¼šå¿…é¡»åŒæ—¶å‡ºç° Project Name å’Œ Crypto è¯æ±‡ï¼Œå¦åˆ™ä¸è¦
    queries.append(f"site:linkedin.com/in/ \"{project_name}\" {base_context} {roles} {negative_filter}")
    queries.append(f"site:linkedin.com/company/ \"{project_name}\" {base_context}")

    # --- Level 3: å…œåº•æœç´¢ (å¦‚æœæ‰¾ä¸åˆ°é¢†è‹±ï¼Œæ‰¾å…¶ä»–æ¥æº) ---
    queries.append(f"\"{project_name}\" {base_context} team listing contact {negative_filter}")
    
    return queries

def execute_search_layer(queries, max_results=5):
    all_results = []
    seen_urls = set()
    
    with st.status("ğŸ¦… æ­£åœ¨æ‰§è¡Œç€‘å¸ƒæµæœç´¢...", expanded=True) as status:
        for q in queries:
            st.write(f"ğŸ“¡ æ‰«æ: {q}")
            try:
                response = tavily.search(
                    query=q,
                    search_depth="advanced",
                    max_results=max_results,
                    include_answer=False
                )
                
                for r in response.get('results', []):
                    # å†æ¬¡åœ¨ä»£ç å±‚åšä¸€æ¬¡è¿‡æ»¤ï¼Œé˜²æ­¢ API æ¼ç½‘ä¹‹é±¼
                    content_lower = (r['title'] + r['content']).lower()
                    if "steak" in content_lower or "restaurant" in content_lower or "menu" in content_lower:
                        continue # ä¸¢å¼ƒé¤å…ç»“æœ
                        
                    if r['url'] not in seen_urls:
                        all_results.append(r)
                        seen_urls.add(r['url'])
                        
            except Exception as e:
                print(f"Query failed: {q} - {e}")
        
        status.update(label=f"âœ… æ•è· {len(all_results)} æ¡æœ‰æ•ˆæƒ…æŠ¥ï¼Œå¼€å§‹ AI åˆ†æ...", state="running", expanded=False)
    
    return all_results

# ============================================================================
# 4. ä¿®å¤ç‰ˆ AI åˆ†æ (Scope Fix + URL Fix)
# ============================================================================

def normalize_url(url):
    """ä¿®å¤ URL è·³è½¬é—®é¢˜"""
    if not url or not isinstance(url, str): return None
    url = url.strip()
    if len(url) < 5 or "none" in url.lower() or "n/a" in url.lower(): return None
    
    # è¡¥å…¨åè®®
    if not url.startswith("http"):
        return "https://" + url
    return url

def analyze_with_deepseek(project_name, search_results, fps):
    # æ„å»º URL ä»“åº“
    url_registry = []
    content_feed = []
    
    for idx, r in enumerate(search_results):
        source_id = f"S{idx+1}"
        # åªè¦æ˜¯é¢†è‹±æˆ–æ¨ç‰¹ï¼Œéƒ½åŠ ç²—æ”¾å…¥æ³¨å†Œè¡¨
        if "linkedin.com" in r['url'] or "x.com" in r['url']:
            url_registry.append(f"[{source_id}] {r['url']} (Title: {r['title']})")
        
        content_feed.append(f"Source [{source_id}]\nURL: {r['url']}\nContent: {r['content'][:800]}\n---\n")
    
    registry_text = "\n".join(url_registry)
    feed_text = "\n".join(content_feed)
    
    prompt = f"""
    Target Project: "{project_name}"
    Context: Crypto/Web3 Industry.
    Detected Fingerprints: {fps}
    
    TASK: Extract verified Team Members and Official Contacts.
    
    CRITICAL RULES:
    1. **NO STEAKHOUSES**: If the content is about food/restaurants (e.g. "Fogo de Chao"), IGNORE IT.
    2. **LINK MATCHING**: You MUST try to find a URL from the "URL REGISTRY" for every person.
       - If you see "Stephen Chen" in Source S1, and S1's URL is a LinkedIn profile, USE IT.
       - Do NOT output "LinkedIn Profile" as text. Output the actual URL or "N/A".
    3. **RECALL**: If you find a person but no link, list them anyway.
    
    URL REGISTRY (Pick links from here):
    {registry_text}
    
    SEARCH CONTENT:
    {feed_text}
    
    OUTPUT JSON:
    {{
        "team": [ {{ "name": "...", "role": "...", "linkedin": "URL/N/A", "twitter": "URL/N/A" }} ],
        "contacts": [ {{ "type": "...", "value": "...", "note": "..." }} ]
    }}
    """
    
    try:
        response = llm.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "You are a JSON extractor. Output valid JSON only."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            response_format={ "type": "json_object" }
        )
        return json.loads(response.choices[0].message.content)
    except Exception as e:
        st.error(f"AI Analysis Error: {e}")
        return None

# ============================================================================
# 5. ä¸»ç•Œé¢
# ============================================================================

st.title("âš”ï¸ Crypto BD Hunter: Architect Edition")
st.markdown("æ™ºèƒ½è¾“å…¥çº é”™ | ç€‘å¸ƒæµæœç´¢ | å®ä½“åº—è¿‡æ»¤")

# --- è¾“å…¥åŒº ---
with st.container():
    col1, col2 = st.columns([3, 1])
    with col1:
        target_project = st.text_input("Project Name", placeholder="e.g. Weex, Monad, Fogo")
    with col2:
        category = st.selectbox("Category", ["Project", "VC", "Exchange"])

    with st.expander("ğŸ•µï¸â€â™‚ï¸ è¾…åŠ©çº¿ç´¢ (ä¹±å¡«ä¹Ÿæ²¡äº‹ï¼Œæˆ‘ä¼šè‡ªåŠ¨è¯†åˆ«)", expanded=True):
        col3, col4 = st.columns(2)
        with col3:
            # å³ä½¿è¿™é‡Œå¡«äº†å®˜ç½‘ï¼Œä¸‹é¢ä»£ç ä¹Ÿèƒ½è¯†åˆ«
            input_twitter = st.text_input("Official Twitter (or Website)", placeholder="Paste any link here")
        with col4:
            # å³ä½¿è¿™é‡Œå¡«äº†æ¨ç‰¹ï¼Œä¸‹é¢ä»£ç ä¹Ÿèƒ½è¯†åˆ«
            input_website = st.text_input("Official Website (or Twitter)", placeholder="Paste any link here")

# --- é€»è¾‘æ ¸å¿ƒ ---
if st.button("ğŸš€ å¯åŠ¨æ·±æ½œæ¨¡å¼", type="primary"):
    if not target_project:
        st.toast("âš ï¸ è¯·è¾“å…¥é¡¹ç›®åç§°")
        st.stop()
        
    # 1. æ™ºèƒ½è¯†åˆ«æŒ‡çº¹ (ä¿®å¤ Input Error)
    fps = auto_detect_fingerprints(input_website, input_twitter)
    
    # æ˜¾ç¤ºè¯†åˆ«ç»“æœç»™ç”¨æˆ·çœ‹
    if fps['twitter_handle'] or fps['domain']:
        st.success(f"ğŸ§¬ æˆåŠŸæå–æŒ‡çº¹: Handle=[@{fps['twitter_handle']}] | Domain=[{fps['domain']}]")
    else:
        st.info("âš ï¸ æœªæ£€æµ‹åˆ°æœ‰æ•ˆæŒ‡çº¹ï¼Œå°†ä½¿ç”¨é€šç”¨æœç´¢æ¨¡å¼ã€‚")
    
    # 2. ç”Ÿæˆå¹¶æ‰§è¡Œæœç´¢
    queries = generate_waterfall_queries(target_project, category, fps)
    raw_data = execute_search_layer(queries)
    
    # 3. AI åˆ†æ (ä¿®å¤ Scope Error)
    ai_result = None  # åˆå§‹åŒ–å˜é‡
    
    if raw_data:
        with st.spinner("ğŸ§  æ­£åœ¨æ¸…æ´—æ•°æ®å¹¶æ’é™¤æ— å…³å®ä½“..."):
            ai_result = analyze_with_deepseek(target_project, raw_data, fps)
    else:
        st.error("âŒ å…¨ç½‘æœªæ‰¾åˆ°ç›¸å…³ Crypto ä¿¡æ¯ã€‚å¯èƒ½åŸå› ï¼šé¡¹ç›®åæ‹¼å†™é”™è¯¯æˆ–è¯¥é¡¹ç›®æ²¡æœ‰ä»»ä½•å…¬å¼€ Web3 è¶³è¿¹ã€‚")
    
    # 4. ç»“æœå±•ç¤º
    if ai_result:
        # --- Team ---
        st.subheader("ğŸ‘¥ æ ¸å¿ƒå›¢é˜Ÿ (Verified)")
        if ai_result.get("team"):
            df_team = pd.DataFrame(ai_result["team"])
            # ä¿®å¤ URL
            for col in ["linkedin", "twitter"]:
                if col in df_team.columns:
                    df_team[col] = df_team[col].apply(normalize_url)
            
            st.dataframe(
                df_team,
                column_config={
                    "linkedin": st.column_config.LinkColumn("LinkedIn", display_text="View Profile"),
                    "twitter": st.column_config.LinkColumn("Twitter", display_text="Open X"),
                },
                use_container_width=True,
                hide_index=True
            )
        else:
            st.warning("æœªæ‰¾åˆ°ä¸ªäººæ¡£æ¡ˆã€‚")

        # --- Contacts ---
        st.subheader("ğŸ“¬ å®˜æ–¹æ¸ é“")
        if ai_result.get("contacts"):
            df_contacts = pd.DataFrame(ai_result["contacts"])
            if "value" in df_contacts.columns:
                df_contacts["value"] = df_contacts["value"].apply(normalize_url)
                
            st.dataframe(
                df_contacts,
                column_config={
                    "value": st.column_config.LinkColumn("Link", display_text="Open Link")
                },
                use_container_width=True,
                hide_index=True
            )
        
        # --- Export ---
        st.divider()
        try:
            # å®‰å…¨å¯¼å‡ºé€»è¾‘
            export_data = []
            for t in ai_result.get("team", []):
                export_data.append({"Type": "Person", "Name": t.get('name'), "Role": t.get('role'), "Link": t.get('linkedin')})
            for c in ai_result.get("contacts", []):
                export_data.append({"Type": "Channel", "Name": c.get('type'), "Desc": c.get('note'), "Link": c.get('value')})
            
            if export_data:
                csv = pd.DataFrame(export_data).to_csv(index=False).encode('utf-8')
                st.download_button("ğŸ“¥ å¯¼å‡ºç»“æœ", data=csv, file_name=f"{target_project}_Hunter_Report.csv")
        except Exception as e:
            st.error(f"å¯¼å‡ºå‡†å¤‡å¤±è´¥: {e}")